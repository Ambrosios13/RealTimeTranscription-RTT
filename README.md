# RealTimeTranscription-RTT

# RealTimeTranscription-RTT ğŸ™ï¸â¡ï¸ğŸ“

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Whisper](https://img.shields.io/badge/OpenAI-Whisper-green.svg)](https://github.com/openai/whisper)

Uma aplicaÃ§Ã£o desktop para transcriÃ§Ã£o de Ã¡udio em tempo real usando modelos Whisper da OpenAI, com interface grÃ¡fica intuitiva desenvolvida em PyQt6.

![RTT Screenshot](https://via.placeholder.com/800x450.png?text=RealTimeTranscription+Screenshot)

## ğŸŒŸ CaracterÃ­sticas

- âš¡ **TranscriÃ§Ã£o em tempo real** - Converte fala em texto enquanto vocÃª fala
- ğŸ”„ **Processamento em chunks** - Processa o Ã¡udio em segmentos de 5 segundos
- ğŸ§  **MÃºltiplos modelos Whisper** - Suporte para tiny, base, small, medium e large
- ğŸ’» **SeleÃ§Ã£o de dispositivo** - Escolha entre CPU ou GPU (CUDA) para processamento
- ğŸ¤ **SeleÃ§Ã£o de microfone** - CompatÃ­vel com mÃºltiplos dispositivos de entrada
- ğŸ’¾ **GravaÃ§Ã£o de Ã¡udio** - OpÃ§Ã£o para salvar o Ã¡udio em formato WAV
- ğŸŒ™ **Tema escuro** - Interface com tema dark mode para reduzir fadiga visual
- ğŸ‡§ğŸ‡· **Suporte ao portuguÃªs** - Otimizado para transcriÃ§Ã£o em portuguÃªs

## ğŸ“‹ Requisitos

- Python 3.8 ou superior
- PyQt6
- sounddevice
- numpy
- PyTorch
- OpenAI Whisper
- qdarkstyle

## ğŸš€ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/Ambrosios13/RealTimeTranscription-RTT.git
cd RealTimeTranscription-RTT
```

2. Crie e ative um ambiente virtual (recomendado):
```bash
python -m venv venv
# No Windows:
venv\Scripts\activate
# No Linux/Mac:
source venv/bin/activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Execute a aplicaÃ§Ã£o:
```bash
python main.py
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Modelos DisponÃ­veis
O tamanho do modelo afeta diretamente a qualidade da transcriÃ§Ã£o e o consumo de recursos:

| Modelo  | Qualidade | RAM | Velocidade |
|---------|-----------|-----|------------|
| tiny    | BÃ¡sica    | ~1GB  | RÃ¡pido     |
| base    | Boa       | ~1GB  | Moderado   |
| small   | Melhor    | ~2GB  | Mais lento |
| medium  | Excelente | ~5GB  | Lento      |
| large   | Superior  | ~10GB | Muito lenta|

### OpÃ§Ãµes de Processamento
- **CPU**: Funciona em qualquer computador, mas pode ser mais lento
- **GPU (CUDA)**: Requer uma placa NVIDIA compatÃ­vel, mas oferece velocidade significativamente superior

## ğŸ“± Como Usar

1. **Selecione o hardware**: Escolha entre CPU ou GPU para processamento
2. **Escolha o modelo**: Selecione o tamanho do modelo Whisper
3. **Selecione o microfone**: Escolha o dispositivo de entrada de Ã¡udio
4. **Configure a gravaÃ§Ã£o**: Marque a opÃ§Ã£o para salvar Ã¡udio, se desejado
5. **Inicie a transcriÃ§Ã£o**: Clique em "Iniciar" e comece a falar
6. **Visualize o texto**: Veja a transcriÃ§Ã£o aparecendo em tempo real
7. **Finalize**: Clique em "Parar" quando terminar

## ğŸ› ï¸ Estrutura do Projeto

```
RealTimeTranscription-RTT/
â”œâ”€â”€ main.py              # Ponto de entrada da aplicaÃ§Ã£o
â”œâ”€â”€ ui.py                # Interface grÃ¡fica do usuÃ¡rio
â”œâ”€â”€ transcriber.py       # Motor de transcriÃ§Ã£o com Whisper
â”œâ”€â”€ audio_recorder.py    # Captura e processamento de Ã¡udio
â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes globais
â”œâ”€â”€ .gitignore           # Arquivos ignorados pelo Git
â”œâ”€â”€ LICENSE              # Arquivo de licenÃ§a MIT
â””â”€â”€ README.md            # Este arquivo
```

## ğŸ” Detalhes TÃ©cnicos

A aplicaÃ§Ã£o funciona dividindo o fluxo de Ã¡udio em chunks de 5 segundos, que sÃ£o processados pelo modelo Whisper para gerar transcriÃ§Ãµes de texto. A interface grÃ¡fica PyQt6 permite uma experiÃªncia de usuÃ¡rio fluida enquanto os processos intensivos sÃ£o executados em threads separadas para evitar o congelamento da interface.

### Processamento de Ãudio
- Taxa de amostragem: 16kHz (formato padrÃ£o para Whisper)
- DuraÃ§Ã£o do chunk: 5 segundos
- Formato de gravaÃ§Ã£o: WAV mono 16-bit

## ğŸ“ˆ Roadmap de Desenvolvimento

- [ ] Adicionar suporte para mais idiomas
- [ ] Implementar exportaÃ§Ã£o de texto para diversos formatos
- [ ] Adicionar reconhecimento de pontuaÃ§Ã£o automÃ¡tica
- [ ] Implementar identificaÃ§Ã£o de falantes
- [ ] Adicionar opÃ§Ã£o de traduÃ§Ã£o em tempo real

## ğŸ¤” SoluÃ§Ã£o de Problemas

**Problema**: NÃ£o detecta meu microfone.
**SoluÃ§Ã£o**: Verifique se o microfone estÃ¡ conectado e funcionando. Talvez seja necessÃ¡rio reiniciar a aplicaÃ§Ã£o.

**Problema**: Erro ao carregar modelo Whisper.
**SoluÃ§Ã£o**: Verifique sua conexÃ£o com a internet e se hÃ¡ espaÃ§o disponÃ­vel no disco. Os modelos maiores requerem download e espaÃ§o substancial.

**Problema**: TranscriÃ§Ã£o muito lenta.
**SoluÃ§Ã£o**: Tente usar um modelo menor (tiny ou base) ou ative o processamento por GPU se disponÃ­vel.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- [OpenAI Whisper](https://github.com/openai/whisper) pelo incrÃ­vel modelo de reconhecimento de fala
- [PyQt6](https://www.riverbankcomputing.com/software/pyqt/) pela biblioteca de interface grÃ¡fica
- [sounddevice](https://python-sounddevice.readthedocs.io/) pela captura de Ã¡udio
- [QDarkStyle](https://github.com/ColinDuquesnoy/QDarkStyleSheet) pelo tema escuro
